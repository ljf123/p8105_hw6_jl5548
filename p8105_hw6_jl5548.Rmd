---
title: "p8105_hw6_jl5548"
author: "J L"
date: "November 14, 2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dplyr)
library(ggridges)
library(viridis)
library(modelr)
library(mgcv)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))

set.seed(1)
```

## Problem 1

**Load and clean the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.).**

```{r}
# load and clean variable names
df_birthweight_origin = read_csv("./data/birthweight.csv") %>% 
  janitor::clean_names() 

# tidy data and store in another dataframe
df_birthweight = df_birthweight_origin %>% 
  mutate(  # convert numeric to factor, and categorize to corresponding label
    babysex = factor(
      case_when(
        babysex == 1 ~ "male",
        babysex == 2 ~ "female"
      )
    ), 
    frace = factor(
      case_when(
        frace == 1 ~ "White",
        frace == 2 ~ "Black",
        frace == 3 ~ "Asian",
        frace == 4 ~ "Puerto Rican",
        frace == 8 ~ "Other",
        frace == 9 ~ "Unknown"
      )
    ),
    malform = factor(
      case_when(
        malform == 0 ~ "absent",
        malform == 1 ~ "present"
      )
    ), 
    mrace = factor(
      case_when(
        mrace == 1 ~ "White",
        mrace == 2 ~ "Black",
        mrace == 3 ~ "Asian",
        mrace == 4 ~ "Puerto Rican",
        mrace == 8 ~ "Other"
      )
    )
  )

# check for missing data
anyNA(df_birthweight)

# display tidied dataset
df_birthweight
```


**Propose a regression model for birthweight. This model may be based on a hypothesized structure for the factors that underly birthweight, on a data-driven model-building process, or a combination of the two. Describe your modeling process and show a plot of model residuals against fitted values – use add_predictions and add_residuals in making this plot.**

I proposed that baby's birth weight as an outcome that may depend on baby's head circumference at birth, baby's length at birth, and mother's weight at delivery. I fit the initial proposed model in the following code chunk using lm() function.

```{r}
## propose a regression model for birthweight (outcome), with bhead, blength, delwt as predictors
model_proposed = lm(bwt ~ bhead + blength + delwt, data = df_birthweight) 
## use the broom package to tidy the coefficient table and reveal results
model_proposed %>% broom::tidy()
```

plot of model residuals against fitted values:

```{r}
## show a plot of model residuals against fitted values
df_birthweight %>% 
  ## add predictions (fitted values)
  modelr::add_predictions(model_proposed) %>% 
  ## add residuals
  modelr::add_residuals(model_proposed) %>% 
  ggplot(aes(x = resid, y = pred)) + 
  geom_point() +
  labs(
    title = "model residuals against fitted values",
    x = "residuals",
    y = "fitted values"
  )
```


**Compare your model to two others:**

__* One using length at birth and gestational age as predictors (main effects only)__

```{r}
## fit a regression model for birthweight (outcome), with blength and gaweeks as predictors
fit1 = lm(bwt ~ blength + gaweeks, data = df_birthweight)
## tidy and reveal results
fit1 %>% broom::tidy()
```

__* One using head circumference, length, sex, and all interactions (including the three-way interaction) between these__

```{r}
## fit a regression model for birthweight (outcome), with bhead, blength, babysex, and interactions as predictors
fit2 = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = df_birthweight)
## tidy and reveal results
fit2 %>% broom::tidy()
```

**Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate.**

```{r}
## preforms the training / testing split 100 times, and stores the datasets
cv_df = crossv_mc(df_birthweight, 100)
cv_df =
  cv_df %>% 
  ## turn the training and testing data as tibble
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  ) %>% 
  ## fit 3 models for the training data
  mutate(
    proposed_mod  = map(train, ~lm(bwt ~ bhead + blength + delwt, data = .x)),
    fit1_mod  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    fit2_mod  = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x)) 
  ) %>% 
  ## calculate RMSEs for 3 models on the testing data
  mutate(
    rmse_proposed = map2_dbl(proposed_mod, test, ~rmse(model = .x, data = .y)),
    rmse_fit1 = map2_dbl(fit1_mod, test, ~rmse(model = .x, data = .y)),
    rmse_fit2 = map2_dbl(fit2_mod, test, ~rmse(model = .x, data = .y))
  )

## plot the distribution of RMSE values for each model to compare
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  labs(title = "distribution of RMSE values for each model")
```

As shown in the plot, the proposed model (baby's birth weight as an outcome that may depend on baby's head circumference at birth, baby's length at birth, and mother's weight at delivery) has the lowest RMSE values. Therefore, we can conclude that the initially proposed model is better than the other two (the main effect model and the model with interactions).



## Problem 2

**For this problem, we’ll use the 2017 Central Park weather data that we’ve seen elsewhere. The code chunk below (adapted from the course website) will download these data.**

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


**Use 5000 bootstrap samples and, for each bootstrap sample, produce estimates of these two quantities. **

```{r}
## generate 5000 bootstrap samples with replacement
bootstrap_samples = weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy),
    quantities = map(models, broom::glance)
  ) %>% 
  select(-strap, -models) %>% 
  unnest(results, quantities)

## separate the results into 2 data sets for further calculation for the estimates of r_sqaure and log(beta0*beta1)
r_square = bootstrap_samples %>% 
  filter(term == "tmin")
log_estimate = bootstrap_samples %>% 
  select(.id, term, estimate) %>% 
  pivot_wider(
    id_cols = .id,
    names_from = term,
    values_from = estimate
  ) %>% 
  janitor::clean_names() %>% 
  mutate(log_estimate = log(intercept * tmin))
```


**Plot the distribution of your estimates, and describe these in words. **

```{r}
## plot the distribution of r_square estimate
r_square %>% 
  ggplot(aes(x = r.squared)) +
  geom_density(fill = "wheat") +
  labs(
    title = "distribution of r square estimate",
    x = "estimate of r square",
    y = "density"
  )

## plot the distribution of log_estimate
log_estimate %>% 
  ggplot(aes(x = log_estimate)) +
  geom_density(fill = "slategray2") +
  labs(
    title = "distribution of log estimate",
    x = "estimate of log",
    y = "density"
  )
```

As shown by the plots of distributions, both r_square and log estimates have normal distributions. Comparatively, the log estimate distribution has a heavier tail, indicating potential dispersion of data on the tail.


**Using the 5000 bootstrap estimates, identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for r̂2 and log(β̂0∗β̂1). Note: broom::glance() is helpful for extracting r̂2 from a fitted regression, and broom::tidy() (with some additional wrangling) should help in computing log(β̂0∗β̂1).**

To find and plot the 95% confidence interval (in red lines) for estimated r_square:

```{r}
## find the 2.5% and 97.5% quantiles to provide a 95% confidence interval for r^2
CI_r_square = r_square %>% 
  pull(r.squared) %>% 
  quantile(., c(0.025, 0.975))
CI_r_square

## plot the 2.5% and 97.5% quantiles in the distribution graph
r_square %>% 
  ggplot(aes(x = r.squared)) +
  geom_density(fill = "wheat") +
  geom_vline(aes(xintercept = CI_r_square[[1]]), color = "red") +
  geom_vline(aes(xintercept = CI_r_square[[2]]), color = "red") +
  labs(
    title = "distribution of r square estimate with 95% CI",
    x = "estimate of r square",
    y = "density"
  )
```

To find and plot the 95% confidence interval (in red lines) for estimated log:

```{r}
## find the 2.5% and 97.5% quantiles to provide a 95% confidence interval for r^2
CI_log = log_estimate %>% 
  pull(log_estimate) %>% 
  quantile(., c(0.025, 0.975))
CI_log

## plot the 2.5% and 97.5% quantiles in the distribution graph
log_estimate %>% 
  ggplot(aes(x = log_estimate)) +
  geom_density(fill = "slategray2") +
  geom_vline(aes(xintercept = CI_log[[1]]), color = "red") +
  geom_vline(aes(xintercept = CI_log[[2]]), color = "red") +
  labs(
    title = "distribution of log estimate with 95% CI",
    x = "estimate of log",
    y = "density"
  )
```

